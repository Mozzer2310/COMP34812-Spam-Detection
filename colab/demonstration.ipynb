{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPna8RyFG6rS8qmTKQQx5eD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Install and import the required packages\n"],"metadata":{"id":"tCvGciMAuYoR"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dp5xZg1RuYI6","executionInfo":{"status":"ok","timestamp":1682523331320,"user_tz":-60,"elapsed":17483,"user":{"displayName":"Tony Lay","userId":"12991364819392579390"}},"outputId":"b04fe735-d07d-4c7b-fbcc-922d0cc8fac4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.24.3)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (2.0.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2023.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.2.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install numpy transformers pandas scikit-learn torch matplotlib datasets"]},{"cell_type":"code","source":["import transformers\n","import json\n","import numpy as np\n","import matplotlib\n","import torch \n","import pandas as pd\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, DistilBertForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","from datasets import load_metric\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ljQ9YqtU7f0U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682523363380,"user_tz":-60,"elapsed":32064,"user":{"displayName":"Tony Lay","userId":"12991364819392579390"}},"outputId":"27d414ab-29bf-4b6a-d4a5-8a9ee90dc275"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Define data pre-processing functions"],"metadata":{"id":"lV3ihT5MusbW"}},{"cell_type":"code","source":["def get_topics_from_csv(file_path):\n","  \"\"\"Retrieves list of topic keywords from a topic csv file\n","  Args:\n","    file_path (str): file path to topic csv file\n","  Returns:\n","    topic_dict (dict): dictionary mapping from video_id to a list of topic keywords\n","  \"\"\"\n","  # Dataframe of csv file\n","  df = pd.read_csv(file_path)\n","\n","  # Create a dictionary mapping from video_id to their topics\n","  topic_dict = dict()\n","  video_ids = list(df['video_id'].unique())\n","  for video_id in video_ids:\n","    query = f\"video_id=='{video_id}'\"\n","    topic_keywords = df.query(query)['topic_keywords'].iloc[0]\n","    topic_dict[video_id] = topic_keywords\n","\n","  return topic_dict\n","\n","def text_to_label(cls):\n","  \"\"\"Converts class to an integer label\n","  Args:\n","    cls (str): class\n","  Returns:\n","    label (int): integer label in set {0,1,2}, returns -1 if there is an unidentifiable class\n","  \"\"\"\n","  if cls == \"spam\":\n","    return 0\n","  elif cls == \"neutral\":\n","    return 1\n","  elif cls == \"ham\":\n","    return 2\n","  else:\n","    return -1\n","\n","def parse_comment(comment):\n","  \"\"\"Parses a comment in a format suitable for the custom tokenizer\n","  Args:\n","    comment (str): raw comment string in the comment retrieval format\n","  Returns:\n","    parsed_comment (str): parsed string\n","  \"\"\"  \n","  if '[MAIN]' in comment:\n","    return comment\n","  else:\n","    return f\"[MAIN] {comment}\"\n","    \n","def get_comments_from_csv(file_path):\n","  \"\"\"Retrieve comment data from a specified .csv file\n","  Args:\n","      file_name (str): .csv file name\n","  Returns:\n","      comments_by_videoid (dict): dictionary mapping from video ID to its list of comments\n","      video_name_dict (dict): dictionary mapping from video ID its video name\n","  \"\"\"\n","  if file_path[-4:] != '.csv':\n","      file_path += '.csv'\n","\n","   # Dataframe of csv file\n","  df = pd.read_csv(file_path)\n","\n","  # Dictionary mapping from video_id to a list containing: username, parsed comment and label\n","  info_dict = dict()\n","\n","  video_ids = list(df['video_id'].unique())\n","  for video_id in video_ids:\n","      query = f\"video_id=='{video_id}'\"\n","      comments = list(df.query(query)['comment'])\n","      usernames = list(df.query(query)['username'])\n","      labels = list(df.query(query)['class'])\n","      info = []\n","      for i in range(0,len(comments)):\n","        label = text_to_label(labels[i])\n","        if label == -1: # Ignore any classes that are not in the set {0,1,2}\n","          continue \n","        info.append([f\"[USER] {usernames[i]} {parse_comment(comments[i])} \",label])\n","\n","      info_dict[video_id] = info\n","      \n","  return info_dict\n","\n","def create_dataset(data_path,dataset_filename):\n","  \"\"\"Create a dataset from a .csv file\n","  Args:\n","      data_path (str): path to the data folder\n","      dataset_filename (str): name of the dataset file\n","  Returns:\n","      dataset (list): dataset where each data item contains a sentence pair (comment, topic keywords)\n","      labels (list): list of labels corresponding to the indices in the dataset\n","  \"\"\"\n","  topic_dict = get_topics_from_csv(f\"{data_path}/topics/{dataset_filename}-topics.csv\")\n","  info_dict = get_comments_from_csv(f\"{data_path}/labelled/{dataset_filename}\")\n","\n","  video_ids = topic_dict.keys()\n","  dataset = []\n","  labels = []\n","  for video_id in video_ids:\n","    for comment_data in info_dict[video_id]:\n","      data_sample = (comment_data[0],topic_dict[video_id])\n","      dataset.append(data_sample)\n","      labels.append(comment_data[1])\n","\n","  return dataset, labels"],"metadata":{"id":"5S2Vo4Umurfo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Prepare model and tokenizer"],"metadata":{"id":"jlpWI1JPxpT0"}},{"cell_type":"code","source":["model_shortcut = \"distilbert-base-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_shortcut)\n","model = AutoModelForSequenceClassification.from_pretrained(model_shortcut, num_labels=3)\n","\n","# Add custom tokens to tokenizer\n","num_added_toks = tokenizer.add_tokens(['[USER]','[MAIN]','[REPLY]'], special_tokens=True)\n","model.resize_token_embeddings(len(tokenizer))\n","\n","saved_model = DistilBertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/NLU Bert Spam Classification/results/model_0\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YxFDRyJxn6a","executionInfo":{"status":"ok","timestamp":1682523372366,"user_tz":-60,"elapsed":8989,"user":{"displayName":"Tony Lay","userId":"12991364819392579390"}},"outputId":"4c68536d-a2d1-4f2a-e530-91a2b5aa1d8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["# Import modules required for demonstration"],"metadata":{"id":"_d_AKzt--4mt"}},{"cell_type":"code","source":["!pip install pyLDAvis gensim spacy"],"metadata":{"id":"k2UWOhZu2a2R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682523403268,"user_tz":-60,"elapsed":30912,"user":{"displayName":"Tony Lay","userId":"12991364819392579390"}},"outputId":"199390c7-8770-434f-8a67-fd38bedfbbe7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.9/dist-packages (3.4.1)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (3.5.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.2.0)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (2.8.4)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.2.2)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (2.0.1)\n","Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.24.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (1.10.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (67.7.2)\n","Requirement already satisfied: funcy in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (2.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from pyLDAvis) (3.1.2)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.9)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.8)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy) (8.1.9)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.4.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.7.0)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.1.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.10.7)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (4.65.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.4)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.7)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (23.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.27.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=2.0.0->pyLDAvis) (2022.7.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->pyLDAvis) (2.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n"]}]},{"cell_type":"code","source":["import gensim\n","import gensim.corpora as corpora\n","from gensim.utils import simple_preprocess\n","from gensim.parsing.preprocessing import preprocess_string, strip_punctuation,strip_numeric\n","import spacy\n","import pyLDAvis\n","import pyLDAvis.gensim \n","import string\n","import nltk\n","import googleapiclient.discovery\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmUUAR0s_Rb0","executionInfo":{"status":"ok","timestamp":1682523407320,"user_tz":-60,"elapsed":4063,"user":{"displayName":"Tony Lay","userId":"12991364819392579390"}},"outputId":"2717e984-ac8b-47e9-f7b0-4e73683b301d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# Demonstration"],"metadata":{"id":"nbplnn4syAej"}},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/NLU Bert Spam Classification/scripts')\n","\n","import ModelTopics\n","import GetComments\n","import GetChannel\n","\n","def create_video_dict(video_id):\n","  \"\"\"Create a dict mapping from video id to a dict containing data about the video, to be used as input for topic modelling\n","  Args:\n","    video_id (str): YouTube video id\n","  Returns:\n","    video_dict (dict): dict mapping from video id to a dict containing data about the video\n","  \"\"\"\n","  youtube_comments, video_name = GetComments.getComments(video_id)\n","  channel_name = GetChannel.getChannel(video_id)\n","  data_dict = {'comments': youtube_comments,\n","               'video_name': video_name,\n","               'channel_name': channel_name}\n","  video_dict = {video_id: data_dict}\n","  return video_dict\n","\n","# Input data here\n","video_link = 'https://www.youtube.com/watch?v=nqJiWbD08Yw'\n","username = 'professional poster'\n","comment = \"I love Tom's narration so much, but his ability to look both young and old at the same time creates sort of an uncanny valley, which somehow even improves the experience of watching these videos\"\n","\n","video_id = video_link.partition(\"watch?v=\")[2]\n","video_dict = create_video_dict(video_id)\n","topic_keywords = \", \".join(list(ModelTopics.get_topics(video_dict)[video_id]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k41a8eFax_Go","executionInfo":{"status":"ok","timestamp":1682524165256,"user_tz":-60,"elapsed":15344,"user":{"displayName":"Tony Lay","userId":"12991364819392579390"}},"outputId":"6354d826-2593-4d85-c956-ca2d63f35421"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Processing 1/1 (nqJiWbD08Yw)\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","# Convert input into a suitable encoded sequence\n","input_sequence = f\"[USER] {username} {parse_comment(comment)}\"\n","input_encoding = tokenizer(comment,topic_keywords, padding=\"max_length\", truncation='only_first')\n","\n","# Create pipeline for custom input sequences\n","pipe = pipeline(\"text-classification\", model=saved_model, tokenizer=tokenizer)\n","pipe(input_sequence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBpjX_tzEEa8","executionInfo":{"status":"ok","timestamp":1682524165257,"user_tz":-60,"elapsed":11,"user":{"displayName":"Tony Lay","userId":"12991364819392579390"}},"outputId":"ed65e3e3-7fe3-4973-fb97-9867f7ed933e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'label': 'LABEL_2', 'score': 0.5994858741760254}]"]},"metadata":{},"execution_count":12}]}]}